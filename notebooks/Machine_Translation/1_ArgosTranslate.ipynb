{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3acbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import subprocess\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bad71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/o4u_preprocessed_messages_Jun_07_2025.json\") as f:\n",
    "    posts = json.load(f)\n",
    "\n",
    "posts = posts[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fc092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://localhost:5000/translate\"\n",
    "HEALTH_CHECK_URL = \"http://localhost:5000/languages\"\n",
    "USER_LANGUAGE = \"ru\"\n",
    "THREAD_COUNTS = [1, 2, 4, 8]\n",
    "NUM_RUNS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583c1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_server_ready(timeout: int = 10) -> bool:\n",
    "    start = time.time()\n",
    "    while (time.time() - start) < timeout:\n",
    "        try:\n",
    "            if requests.get(url=HEALTH_CHECK_URL).status_code == 200:\n",
    "                return True\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            time.sleep(0.5)\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_server_down(host: str = \"127.0.0.1\", port: int = 5000, timeout: int = 20) -> bool:\n",
    "    start = time.time()\n",
    "    while (time.time() - start) < timeout:\n",
    "        try:\n",
    "            with socket.create_connection(address=(host, port), timeout=1) as sock:\n",
    "                time.sleep(0.5)\n",
    "        except (ConnectionRefusedError, TimeoutError):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75b69269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing latency with threads=1 ===\n",
      "Starting the server\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Network machine_translation_default  Creating\n",
      " Network machine_translation_default  Created\n",
      " Container libretranslate  Creating\n",
      " Container libretranslate  Created\n",
      " Container libretranslate  Starting\n",
      " Container libretranslate  Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready\n",
      "Starting the benchmark\n",
      "Starting run 1/3\n",
      "Run 1/3 completed in 114.754s\n",
      "Starting run 2/3\n",
      "Run 2/3 completed in 111.426s\n",
      "Starting run 3/3\n",
      "Run 3/3 completed in 113.046s\n",
      "Shutting the server down\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container libretranslate  Stopping\n",
      " Container libretranslate  Stopped\n",
      " Container libretranslate  Removing\n",
      " Container libretranslate  Removed\n",
      " Network machine_translation_default  Removing\n",
      " Network machine_translation_default  Removed\n",
      " Network machine_translation_default  Creating\n",
      " Network machine_translation_default  Created\n",
      " Container libretranslate  Creating\n",
      " Container libretranslate  Created\n",
      " Container libretranslate  Starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is down\n",
      "\n",
      "\n",
      "\n",
      "=== Testing latency with threads=2 ===\n",
      "Starting the server\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container libretranslate  Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready\n",
      "Starting the benchmark\n",
      "Starting run 1/3\n",
      "Run 1/3 completed in 113.855s\n",
      "Starting run 2/3\n",
      "Run 2/3 completed in 110.928s\n",
      "Starting run 3/3\n",
      "Run 3/3 completed in 110.854s\n",
      "Shutting the server down\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container libretranslate  Stopping\n",
      " Container libretranslate  Stopped\n",
      " Container libretranslate  Removing\n",
      " Container libretranslate  Removed\n",
      " Network machine_translation_default  Removing\n",
      " Network machine_translation_default  Removed\n",
      " Network machine_translation_default  Creating\n",
      " Network machine_translation_default  Created\n",
      " Container libretranslate  Creating\n",
      " Container libretranslate  Created\n",
      " Container libretranslate  Starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is down\n",
      "\n",
      "\n",
      "\n",
      "=== Testing latency with threads=4 ===\n",
      "Starting the server\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container libretranslate  Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready\n",
      "Starting the benchmark\n",
      "Starting run 1/3\n",
      "Run 1/3 completed in 115.294s\n",
      "Starting run 2/3\n",
      "Run 2/3 completed in 114.491s\n",
      "Starting run 3/3\n",
      "Run 3/3 completed in 113.916s\n",
      "Shutting the server down\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container libretranslate  Stopping\n",
      " Container libretranslate  Stopped\n",
      " Container libretranslate  Removing\n",
      " Container libretranslate  Removed\n",
      " Network machine_translation_default  Removing\n",
      " Network machine_translation_default  Removed\n",
      " Network machine_translation_default  Creating\n",
      " Network machine_translation_default  Created\n",
      " Container libretranslate  Creating\n",
      " Container libretranslate  Created\n",
      " Container libretranslate  Starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is down\n",
      "\n",
      "\n",
      "\n",
      "=== Testing latency with threads=8 ===\n",
      "Starting the server\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container libretranslate  Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is ready\n",
      "Starting the benchmark\n",
      "Starting run 1/3\n",
      "Run 1/3 completed in 116.882s\n",
      "Starting run 2/3\n",
      "Run 2/3 completed in 113.502s\n",
      "Starting run 3/3\n",
      "Run 3/3 completed in 117.546s\n",
      "Shutting the server down\n",
      "Waiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container libretranslate  Stopping\n",
      " Container libretranslate  Stopped\n",
      " Container libretranslate  Removing\n",
      " Container libretranslate  Removed\n",
      " Network machine_translation_default  Removing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is down\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Network machine_translation_default  Removed\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for threads in THREAD_COUNTS:\n",
    "    print(f\"=== Testing latency with {threads=} ===\")\n",
    "\n",
    "    start_sh = f\"LT_THREADS={threads} docker compose up -d\"\n",
    "    stop_sh = \"docker compose down\"\n",
    "\n",
    "    try:\n",
    "        print(\"Starting the server\")\n",
    "        print(\"Waiting...\")\n",
    "        subprocess.run(start_sh, shell=True, check=True)\n",
    "        if not is_server_ready():\n",
    "            raise RuntimeError(f\"Server did not become ready in time\")\n",
    "        print(\"Server is ready\")\n",
    "\n",
    "        times = []\n",
    "        payload = {\n",
    "            \"q\": posts,\n",
    "            \"source\": \"auto\",\n",
    "            \"target\": USER_LANGUAGE,\n",
    "            \"format\": \"text\"\n",
    "        }\n",
    "        print(\"Starting the benchmark\")\n",
    "        for i in range(NUM_RUNS):\n",
    "            print(f\"Starting run {i+1}/{NUM_RUNS}\")\n",
    "            start = time.time()\n",
    "            response = requests.post(url=API_URL, json=payload)\n",
    "            response.raise_for_status()\n",
    "            delta = time.time() - start\n",
    "            times.append(delta)\n",
    "            print(f\"Run {i+1}/{NUM_RUNS} completed in {delta:.3f}s\")\n",
    "        average_batch_latency = sum(times) / len(times)\n",
    "        average_per_post_latency = 1000 * (average_batch_latency / len(posts))\n",
    "        results[threads] = {\n",
    "            \"average_batch_latency_s\": average_batch_latency,\n",
    "            \"average_per_post_latency_ms\": average_per_post_latency,\n",
    "            \"batch_size\": len(posts)\n",
    "        }\n",
    "    except (subprocess.CalledProcessError, requests.exceptions.RequestException, RuntimeError) as e:\n",
    "        print(e)\n",
    "        print(f\"An error ocurred, {threads=} skipped\")\n",
    "    finally:\n",
    "        print(\"Shutting the server down\")\n",
    "        print(\"Waiting...\")\n",
    "        subprocess.run(stop_sh, shell=True, check=True)\n",
    "        if not is_server_down(port=5000):\n",
    "            raise RuntimeError(\"Server did not shut down\")\n",
    "        print(\"Server is down\")\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545ac772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'average_batch_latency_s': 113.07500704129536,\n",
       "  'average_per_post_latency_ms': 565.3750352064768,\n",
       "  'batch_size': 200},\n",
       " 2: {'average_batch_latency_s': 111.87896712621053,\n",
       "  'average_per_post_latency_ms': 559.3948356310526,\n",
       "  'batch_size': 200},\n",
       " 4: {'average_batch_latency_s': 114.56675306955974,\n",
       "  'average_per_post_latency_ms': 572.8337653477987,\n",
       "  'batch_size': 200},\n",
       " 8: {'average_batch_latency_s': 115.97688500086467,\n",
       "  'average_per_post_latency_ms': 579.8844250043234,\n",
       "  'batch_size': 200}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636483ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Corpus BLEU Score: 53.32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "\n",
    "test_data = [\n",
    "    # --- Short & Direct Announcements ---\n",
    "    {\n",
    "        \"source_text\": \"Ultimate Frisbee today at 18:00 by the main IU entrance!\",\n",
    "        \"ground_truth_text\": \"Сегодня в 18:00 у главного входа в Университет Иннополис играем в алтимат фрисби!\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"Poetry evenings ARE BACK!\",\n",
    "        \"ground_truth_text\": \"Поэтические вечера ВОЗВРАЩАЮТСЯ!\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"We are still looking for students to fill various roles for this project!\",\n",
    "        \"ground_truth_text\": \"Мы все еще ищем студентов на различные роли для этого проекта!\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"The deadline for registration was extended!\",\n",
    "        \"ground_truth_text\": \"Срок регистрации был продлен!\"\n",
    "    },\n",
    "    # --- Event Descriptions ---\n",
    "    {\n",
    "        \"source_text\": \"Youth hackathon on creating services for a 'smart building'\",\n",
    "        \"ground_truth_text\": \"Молодежный хакатон по созданию сервисов для 'умного здания'\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"Technical Volunteers needed for DID Summer Forum\",\n",
    "        \"ground_truth_text\": \"Требуются технические волонтеры на Летний форум DID\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"International Fest: International Quest 'Inheritance'\",\n",
    "        \"ground_truth_text\": \"Международный фестиваль: Международный квест 'Наследие'\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"Low Level Programming Club presents a brand-new workshop: Introduction to hobby electronics and IoT with nRF52!\",\n",
    "        \"ground_truth_text\": \"Клуб низкоуровневого программирования представляет новый воркшоп: Введение в хобби-электронику и IoT с nRF52!\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"Guest lecture by Aeroflot CEO advisor, Andrey Polozov-Yablonski on Innovation Management in a Large Company.\",\n",
    "        \"ground_truth_text\": \"Гостевая лекция советника генерального директора Аэрофлота Андрея Полозова-Яблонского на тему Управление инновациями в крупной компании.\"\n",
    "    },\n",
    "    # --- Calls to Action & Invitations ---\n",
    "    {\n",
    "        \"source_text\": \"Aikido Innopolis invites students to join their meetings.\",\n",
    "        \"ground_truth_text\": \"Айкидо Иннополис приглашает студентов присоединиться к своим встречам.\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"To apply fill the form by 30 November.\",\n",
    "        \"ground_truth_text\": \"Для подачи заявки заполните форму до 30 ноября.\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"If you want to work in this project, message AnyaProkhorenko by the end of Friday, November 22.\",\n",
    "        \"ground_truth_text\": \"Если вы хотите работать в этом проекте, напишите AnyaProkhorenko до конца пятницы, 22 ноября.\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"Come, support us and enjoy the game!\",\n",
    "        \"ground_truth_text\": \"Приходите поддержать нас и насладиться игрой!\"\n",
    "    },\n",
    "    # --- Longer, More Complex Descriptions ---\n",
    "    {\n",
    "        \"source_text\": \"The course focuses on development of Hyper Casual Games (due to short development cycle and fast marketability response).\",\n",
    "        \"ground_truth_text\": \"Курс сфокусирован на разработке гипер-казуальных игр (ввиду короткого цикла разработки и быстрого отклика рынка).\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"The project is supervised by Admissions Office, who are able to provide you with further information and materials to deliver a presentation at your school.\",\n",
    "        \"ground_truth_text\": \"Проект курируется Приемной комиссией, которая может предоставить вам дополнительную информацию и материалы для проведения презентации в вашей школе.\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"The aim of the project is to create a community of entrepreneurs who create products with a national flavor.\",\n",
    "        \"ground_truth_text\": \"Цель проекта - создать сообщество предпринимателей, которые создают продукты с национальным колоритом.\"\n",
    "    },\n",
    "    # --- Questions and Informal Text ---\n",
    "    {\n",
    "        \"source_text\": \"Why to stay moody when you can shake your booty?\",\n",
    "        \"ground_truth_text\": \"Зачем грустить, когда можно потанцевать?\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"Experience or creativity - what's more important to win the game?\",\n",
    "        \"ground_truth_text\": \"Опыт или креативность - что важнее для победы в игре?\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"If you can't handle Russian, you'll have to use Google Translate Chrome Extension to be able to navigate through the website.\",\n",
    "        \"ground_truth_text\": \"Если вы не владеете русским языком, вам придется использовать расширение Google Translate для Chrome, чтобы навигироваться по сайту.\"\n",
    "    },\n",
    "    {\n",
    "        \"source_text\": \"For certain achievements in the ICPC and participation in trainings, you can receive academic and scholarship bonuses.\",\n",
    "        \"ground_truth_text\": \"За определенные достижения в ICPC и участие в тренировках вы можете получить академические и стипендиальные бонусы.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "source_texts = [item[\"source_text\"] for item in test_data]\n",
    "payload = {\n",
    "    \"q\": source_texts,\n",
    "    \"source\": \"en\",\n",
    "    \"target\": \"ru\"\n",
    "}\n",
    "response = requests.post(url=API_URL, json=payload)\n",
    "machine_translations = response.json().get(\"translatedText\")\n",
    "\n",
    "human_references = [[item[\"ground_truth_text\"]] for item in test_data]\n",
    "bleu = sacrebleu.corpus_bleu(machine_translations, human_references)\n",
    "print(f\"Overall Corpus BLEU Score: {bleu.score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
